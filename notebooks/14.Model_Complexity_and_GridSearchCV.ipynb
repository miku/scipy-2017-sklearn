{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.521218\n",
      "n_neighbors: 3, average score: 0.713238\n",
      "n_neighbors: 5, average score: 0.742481\n",
      "n_neighbors: 10, average score: 0.706622\n",
      "n_neighbors: 20, average score: 0.629584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a451908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), 'b', label=\"train accuracy\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), 'g', label=\"test accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot uses a reverted x axis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.032834\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.011463\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.053681\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.036514\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.045984\n",
      "C: 0.010000, gamma: 0.010000, average score: -0.150661\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.079760\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.001994\n",
      "C: 0.100000, gamma: 0.001000, average score: 0.023098\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.176660\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.503442\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.471687\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.173430\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.524774\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.630705\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.696792\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.607313\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.635771\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.674207\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.750878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] . C=0.001, gamma=0.001, score=-0.03276747788080514, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] .. C=0.001, gamma=0.001, score=-0.1529529234275644, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] .. C=0.001, gamma=0.001, score=-0.1998817688578407, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .. C=0.001, gamma=0.01, score=-0.03063873568346143, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .. C=0.001, gamma=0.01, score=-0.15080063251166753, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ... C=0.001, gamma=0.01, score=-0.1971222385880096, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .. C=0.001, gamma=0.1, score=-0.021228717551623477, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ... C=0.001, gamma=0.1, score=-0.14189166564785172, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .... C=0.001, gamma=0.1, score=-0.1857245925762676, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] .... C=0.001, gamma=1, score=-0.022701590480666667, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ...... C=0.001, gamma=1, score=-0.1441927022530689, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=-0.18827232490352497, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] . C=0.01, gamma=0.001, score=-0.030423472398951153, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ... C=0.01, gamma=0.001, score=-0.1505664709934218, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .. C=0.01, gamma=0.001, score=-0.19681590460138376, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .. C=0.01, gamma=0.01, score=-0.009302499999100045, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .... C=0.01, gamma=0.01, score=-0.1294700505796138, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ... C=0.01, gamma=0.01, score=-0.17074657147904349, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.07244397694463556, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] .... C=0.01, gamma=0.1, score=-0.04012856976941759, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] .... C=0.01, gamma=0.1, score=-0.06986348287207568, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ...... C=0.01, gamma=1, score=0.051040559719434775, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ...... C=0.01, gamma=1, score=-0.05631645540527708, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ...... C=0.01, gamma=1, score=-0.08118725483951361, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .. C=0.1, gamma=0.001, score=-0.007182899363980866, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=-0.12733965555434446, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .... C=0.1, gamma=0.001, score=-0.1678571557905284, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...... C=0.1, gamma=0.01, score=0.1361820698663786, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.07881487498958073, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.03367795828761644, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.4662217465957127, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5144000147447865, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ...... C=0.1, gamma=0.1, score=0.48766735386066085, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .......... C=0.1, gamma=1, score=0.424943997214455, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.5032970375135553, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.4707002075401091, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.1492413278159217, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.09886291851622986, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.05304968690958433, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5514626323774324, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5563437734177857, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5547388491818561, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.6477176780185718, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.5498080804510654, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.7349948630302138, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.6843441220896525, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.6192247967521916, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7186331419374286, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5612916555070366, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5488276752653443, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5557672459764864, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.5939009751556312, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.4917026673300434, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6343682144826246, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.6539291793260851, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ......... C=10, gamma=0.1, score=0.507669560638049, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ......... C=10, gamma=0.1, score=0.758155291165991, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7564415467238248, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7062479160928494, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7698016116158038, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7442864700299561\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can investigate the performance and much more for each set of parameter values by accessing the `cv_results_` attributes. The `cv_results_` attribute is a dictionary where each key is a string and each value is array. It can therefore be used to make a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.deprecation.DeprecationDict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tir/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tir/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tir/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tir/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/tir/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>-0.127576</td>\n",
       "      <td>-0.011276</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.032767</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>-0.152953</td>\n",
       "      <td>-0.033543</td>\n",
       "      <td>-0.199882</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.070668</td>\n",
       "      <td>0.015748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>-0.125232</td>\n",
       "      <td>-0.009336</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.030639</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>-0.150801</td>\n",
       "      <td>-0.031783</td>\n",
       "      <td>-0.197122</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.070452</td>\n",
       "      <td>0.015878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>-0.115331</td>\n",
       "      <td>-0.000774</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.021229</td>\n",
       "      <td>0.012291</td>\n",
       "      <td>-0.141892</td>\n",
       "      <td>-0.023911</td>\n",
       "      <td>-0.185725</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.069849</td>\n",
       "      <td>0.016406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>-0.117432</td>\n",
       "      <td>-0.001849</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.022702</td>\n",
       "      <td>0.011663</td>\n",
       "      <td>-0.144193</td>\n",
       "      <td>-0.024962</td>\n",
       "      <td>-0.188272</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.070310</td>\n",
       "      <td>0.016421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>-0.124980</td>\n",
       "      <td>-0.009139</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.030423</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>-0.150566</td>\n",
       "      <td>-0.031610</td>\n",
       "      <td>-0.196816</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.070419</td>\n",
       "      <td>0.015894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0       0.001116         0.000464        -0.127576         -0.011276   0.001   \n",
       "1       0.000884         0.000462        -0.125232         -0.009336   0.001   \n",
       "2       0.000721         0.000470        -0.115331         -0.000774   0.001   \n",
       "3       0.000910         0.000409        -0.117432         -0.001849   0.001   \n",
       "4       0.001345         0.000353        -0.124980         -0.009139    0.01   \n",
       "\n",
       "  param_gamma                        params  rank_test_score  \\\n",
       "0       0.001  {'C': 0.001, 'gamma': 0.001}               20   \n",
       "1        0.01   {'C': 0.001, 'gamma': 0.01}               19   \n",
       "2         0.1    {'C': 0.001, 'gamma': 0.1}               16   \n",
       "3           1      {'C': 0.001, 'gamma': 1}               17   \n",
       "4       0.001   {'C': 0.01, 'gamma': 0.001}               18   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0          -0.032767            0.000258          -0.152953   \n",
       "1          -0.030639            0.002376          -0.150801   \n",
       "2          -0.021229            0.012291          -0.141892   \n",
       "3          -0.022702            0.011663          -0.144193   \n",
       "4          -0.030423            0.002574          -0.150566   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0           -0.033543          -0.199882           -0.000544      0.000201   \n",
       "1           -0.031783          -0.197122            0.001400      0.000126   \n",
       "2           -0.023911          -0.185725            0.009298      0.000167   \n",
       "3           -0.024962          -0.188272            0.007752      0.000120   \n",
       "4           -0.031610          -0.196816            0.001619      0.000789   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000097        0.070668         0.015748  \n",
       "1        0.000126        0.070452         0.015878  \n",
       "2        0.000099        0.069849         0.016406  \n",
       "3        0.000092        0.070310         0.016421  \n",
       "4        0.000032        0.070419         0.015894  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.674170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.644209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.640058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.573530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_gamma  mean_test_score\n",
       "19      10           1         0.744286\n",
       "15       1           1         0.674170\n",
       "14       1         0.1         0.644209\n",
       "18      10         0.1         0.640058\n",
       "17      10        0.01         0.573530"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_tiny = cv_results[['param_C', 'param_gamma', 'mean_test_score']]\n",
    "cv_results_tiny.sort_values(by='mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] .. C=0.001, gamma=0.001, score=-0.3990901464048937, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ... C=0.001, gamma=0.01, score=-0.3969642722673339, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ... C=0.001, gamma=0.1, score=-0.38771258338594206, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ...... C=0.001, gamma=1, score=-0.3887211736713678, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .... C=0.01, gamma=0.001, score=-0.396742360577808, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .... C=0.01, gamma=0.01, score=-0.3756973109285944, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ...... C=0.01, gamma=0.1, score=-0.251387958615211, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ........ C=0.01, gamma=1, score=-0.287564210597262, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=-0.37352891668079047, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] .... C=0.1, gamma=0.01, score=-0.12179263427112598, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ...... C=0.1, gamma=0.1, score=0.41672320009279584, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.3588669746164601, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ..... C=1, gamma=0.001, score=-0.09208038671147567, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5564778354210065, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.7339253872307794, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7804801201246243, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5435777521509164, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6001477741337387, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ......... C=10, gamma=0.1, score=0.739594702665292, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8538935773128021, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/14_grid_search.py"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
